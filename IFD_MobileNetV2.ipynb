{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc3b314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sathy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Loading authentic images...\n",
      "Loading tampered images and calculating differences...\n",
      "No authentic match found for Tp_S_CNN_S_N_cha0003_cha00003_00323.tif, using tampered image directly.\n",
      "No authentic match found for Tp_S_NNN_M_N_pla0006_pla00006_01128.tif, using tampered image directly.\n",
      "Train set size: 10091, Test set size: 2523\n",
      "WARNING:tensorflow:From C:\\Users\\sathy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sathy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\sathy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sathy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sathy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sathy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 1\n",
      "Loss: 0.08299383521080017, Accuracy: 0.9739371538162231, Val Loss: 0.04672575369477272, Val Accuracy: 0.9849385619163513\n",
      "631/631 - 183s - loss: 0.0830 - accuracy: 0.9739 - val_loss: 0.0467 - val_accuracy: 0.9849 - 183s/epoch - 291ms/step\n",
      "Starting epoch 2\n",
      "Epoch 2/10\n",
      "Finished epoch 2\n",
      "Loss: 0.04795760661363602, Accuracy: 0.9854325652122498, Val Loss: 0.04245280846953392, Val Accuracy: 0.9857312440872192\n",
      "631/631 - 165s - loss: 0.0480 - accuracy: 0.9854 - val_loss: 0.0425 - val_accuracy: 0.9857 - 165s/epoch - 261ms/step\n",
      "Starting epoch 3\n",
      "Epoch 3/10\n",
      "Finished epoch 3\n",
      "Loss: 0.03111722320318222, Accuracy: 0.9908829927444458, Val Loss: 0.04738790541887283, Val Accuracy: 0.9877130389213562\n",
      "631/631 - 168s - loss: 0.0311 - accuracy: 0.9909 - val_loss: 0.0474 - val_accuracy: 0.9877 - 168s/epoch - 266ms/step\n",
      "Starting epoch 4\n",
      "Epoch 4/10\n",
      "Finished epoch 4\n",
      "Loss: 0.024665286764502525, Accuracy: 0.9914775490760803, Val Loss: 0.048341892659664154, Val Accuracy: 0.9861276149749756\n",
      "631/631 - 158s - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.0483 - val_accuracy: 0.9861 - 158s/epoch - 251ms/step\n",
      "Starting epoch 5\n",
      "Epoch 5/10\n",
      "Finished epoch 5\n",
      "Loss: 0.02930503524839878, Accuracy: 0.9908829927444458, Val Loss: 0.043200548738241196, Val Accuracy: 0.9861276149749756\n",
      "631/631 - 157s - loss: 0.0293 - accuracy: 0.9909 - val_loss: 0.0432 - val_accuracy: 0.9861 - 157s/epoch - 249ms/step\n",
      "Starting epoch 6\n",
      "Epoch 6/10\n",
      "Finished epoch 6\n",
      "Loss: 0.017831791192293167, Accuracy: 0.9950450658798218, Val Loss: 0.04235399514436722, Val Accuracy: 0.9889020919799805\n",
      "631/631 - 152s - loss: 0.0178 - accuracy: 0.9950 - val_loss: 0.0424 - val_accuracy: 0.9889 - 152s/epoch - 241ms/step\n",
      "Starting epoch 7\n",
      "Epoch 7/10\n",
      "Finished epoch 7\n",
      "Loss: 0.016848791390657425, Accuracy: 0.993855893611908, Val Loss: 0.04812385141849518, Val Accuracy: 0.9881094098091125\n",
      "631/631 - 138s - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.0481 - val_accuracy: 0.9881 - 138s/epoch - 219ms/step\n",
      "Starting epoch 8\n",
      "Epoch 8/10\n",
      "Finished epoch 8\n",
      "Loss: 0.01594668999314308, Accuracy: 0.9949460029602051, Val Loss: 0.05349346622824669, Val Accuracy: 0.9892984628677368\n",
      "631/631 - 126s - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0535 - val_accuracy: 0.9893 - 126s/epoch - 200ms/step\n",
      "Starting epoch 9\n",
      "Epoch 9/10\n",
      "Finished epoch 9\n",
      "Loss: 0.023844007402658463, Accuracy: 0.9934595227241516, Val Loss: 0.05076213181018829, Val Accuracy: 0.9889020919799805\n",
      "631/631 - 120s - loss: 0.0238 - accuracy: 0.9935 - val_loss: 0.0508 - val_accuracy: 0.9889 - 120s/epoch - 191ms/step\n",
      "Starting epoch 10\n",
      "Epoch 10/10\n",
      "Finished epoch 10\n",
      "Loss: 0.01726476661860943, Accuracy: 0.9948468804359436, Val Loss: 0.050285715609788895, Val Accuracy: 0.9881094098091125\n",
      "631/631 - 124s - loss: 0.0173 - accuracy: 0.9948 - val_loss: 0.0503 - val_accuracy: 0.9881 - 124s/epoch - 196ms/step\n",
      "158/158 [==============================] - 22s 138ms/step - loss: 0.0503 - accuracy: 0.9881\n",
      "Final test loss: 0.050285715609788895, Final test accuracy: 0.9881094098091125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import gc  # Import garbage collector module\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "def calculate_difference_image(image1, image2):\n",
    "    return cv2.absdiff(image1, image2)\n",
    "\n",
    "class ImageDataGenerator(Sequence):\n",
    "    def __init__(self, images, labels, batch_size):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.images) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.images[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "\n",
    "def load_images_and_difference(authentic_dir, tampered_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    print(\"Loading authentic images...\")\n",
    "    for filename in os.listdir(authentic_dir):\n",
    "        if filename.lower().endswith(('.jpg', '.bmp')):\n",
    "            filepath = os.path.join(authentic_dir, filename)\n",
    "            img = cv2.imread(filepath, cv2.IMREAD_COLOR)\n",
    "            if img is not None:\n",
    "                img_resized = cv2.resize(img, (224, 224)).astype(np.float32) / 255.0\n",
    "                images.append(img_resized)\n",
    "                labels.append(0)\n",
    "\n",
    "    print(\"Loading tampered images and calculating differences...\")\n",
    "    for filename in os.listdir(tampered_dir):\n",
    "        if filename.lower().endswith(('.jpg', '.tif')):\n",
    "            tampered_img = cv2.imread(os.path.join(tampered_dir, filename), cv2.IMREAD_COLOR)\n",
    "            tampered_img_resized = cv2.resize(tampered_img, (224, 224)).astype(np.float32) / 255.0\n",
    "            \n",
    "            match_found = False\n",
    "            parts = filename.split(\"_\")\n",
    "            if len(parts) >= 7:\n",
    "                source_id = parts[4][:3] + \"_\" + parts[4][3:]\n",
    "                target_id = parts[5][:3] + \"_\" + parts[5][3:]\n",
    "                for id_ in [source_id, target_id]:\n",
    "                    for ext in ['.jpg', '.bmp']:\n",
    "                        auth_filename = f\"Au_{id_}{ext}\"\n",
    "                        auth_filepath = os.path.join(authentic_dir, auth_filename)\n",
    "                        if os.path.exists(auth_filepath):\n",
    "                            auth_img = cv2.imread(auth_filepath, cv2.IMREAD_COLOR)\n",
    "                            auth_img_resized = cv2.resize(auth_img, (224, 224)).astype(np.float32) / 255.0\n",
    "                            difference_img = calculate_difference_image(tampered_img_resized, auth_img_resized)\n",
    "                            images.append(difference_img)\n",
    "                            labels.append(1)\n",
    "                            match_found = True\n",
    "                            break\n",
    "            if not match_found:\n",
    "                print(f\"No authentic match found for {filename}, using tampered image directly.\")\n",
    "                images.append(tampered_img_resized)\n",
    "                labels.append(1)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "authentic_dir = 'D:\\SASTRA Files\\Sem-6\\MINI PROJECT\\Digital Image Forgery Detection\\CASIA2 Dataset\\Au'\n",
    "tampered_dir = 'D:\\SASTRA Files\\Sem-6\\MINI PROJECT\\Digital Image Forgery Detection\\CASIA2 Dataset\\Tp'\n",
    "\n",
    "images, labels = load_images_and_difference(authentic_dir, tampered_dir)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "print(f\"Train set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "class TrainingMonitor(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print(f\"Starting epoch {epoch+1}\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"Finished epoch {epoch+1}\")\n",
    "        print(f\"Loss: {logs['loss']}, Accuracy: {logs['accuracy']}, Val Loss: {logs['val_loss']}, Val Accuracy: {logs['val_accuracy']}\")\n",
    "\n",
    "batch_size = 16\n",
    "train_generator = ImageDataGenerator(X_train, y_train, batch_size)\n",
    "test_generator = ImageDataGenerator(X_test, y_test, batch_size)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[TrainingMonitor()],\n",
    "    verbose=2)\n",
    "\n",
    "final_loss, final_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Final test loss: {final_loss}, Final test accuracy: {final_accuracy}\")\n",
    "\n",
    "# Save the entire model\n",
    "model.save('MobileNetV2_BC.h5')\n",
    "print(\"Saved model to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ecf59f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_single_image(test_image_path, reference_image_path):\n",
    "    test_img = cv2.imread(test_image_path, cv2.IMREAD_COLOR)\n",
    "    test_img_resized = cv2.resize(test_img, (224, 224)).astype(np.float32) / 255.0\n",
    "\n",
    "    reference_img = cv2.imread(reference_image_path, cv2.IMREAD_COLOR)\n",
    "    reference_img_resized = cv2.resize(reference_img, (224, 224)).astype(np.float32) / 255.0\n",
    "\n",
    "    difference_img = calculate_difference_image(test_img_resized, reference_img_resized)\n",
    "    difference_img = np.expand_dims(difference_img, axis=0)\n",
    "    return difference_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22ecd5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 879ms/step\n",
      "Prediction (0 for Authentic, 1 for Tampered): [1.]\n",
      "The image is likely tampered.\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "loaded_model = load_model('MobileNetV2_BC.h5')\n",
    "\n",
    "test_image_path = 'D:\\SASTRA Files\\Sem-6\\MINI PROJECT\\Digital Image Forgery Detection\\CASIA2 Dataset\\Au\\Au_nat_00003.jpg'\n",
    "reference_image_path = 'D:\\SASTRA Files\\Sem-6\\MINI PROJECT\\Digital Image Forgery Detection\\CASIA2 Dataset\\Tp\\Tp_D_NNN_S_N_nat00003_cha00096_00623.tif'\n",
    "\n",
    "difference_image = prepare_single_image(test_image_path, reference_image_path)\n",
    "prediction = loaded_model.predict(difference_image)\n",
    "\n",
    "print(f\"Prediction (0 for Authentic, 1 for Tampered): {prediction[0]}\")\n",
    "if prediction[0] > 0.5:\n",
    "    print(\"The image is likely tampered.\")\n",
    "else:\n",
    "    print(\"The image is likely authentic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e9cf262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E1AF85D750> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E1AF85D750> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Prediction (0 for Authentic, 1 for Tampered): [0.93142855]\n",
      "The image is likely tampered.\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "loaded_model = load_model('MobileNetV2_BC.h5')\n",
    "\n",
    "test_image_path = 'D:\\SASTRA Files\\Sem-6\\MINI PROJECT\\Digital Image Forgery Detection\\CASIA2 Dataset\\Au\\Au_sec_10109.jpg'\n",
    "reference_image_path = 'D:\\SASTRA Files\\Sem-6\\MINI PROJECT\\Digital Image Forgery Detection\\CASIA2 Dataset\\Tp\\Tp_D_NRN_M_N_sec10105_sec10109_10333.tif'\n",
    "\n",
    "difference_image = prepare_single_image(test_image_path, reference_image_path)\n",
    "prediction = loaded_model.predict(difference_image)\n",
    "\n",
    "print(f\"Prediction (0 for Authentic, 1 for Tampered): {prediction[0]}\")\n",
    "if prediction[0] > 0.5:\n",
    "    print(\"The image is likely tampered.\")\n",
    "else:\n",
    "    print(\"The image is likely authentic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4f52fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 728ms/step\n",
      "Prediction (0 for Authentic, 1 for Tampered): [0.99999994]\n",
      "The image is likely tampered.\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "loaded_model = load_model('MobileNetV2_BC.h5')\n",
    "\n",
    "test_image_path = 'D:\\SASTRA Files\\Sem-6\\MINI PROJECT\\Digital Image Forgery Detection\\CASIA2 Dataset\\Au\\Au_pla_00050.jpg'\n",
    "reference_image_path = 'D:\\SASTRA Files\\Sem-6\\MINI PROJECT\\Digital Image Forgery Detection\\CASIA2 Dataset\\Tp\\Tp_D_NRN_S_N_ind00009_pla00050_10423.tif'\n",
    "\n",
    "difference_image = prepare_single_image(test_image_path, reference_image_path)\n",
    "prediction = loaded_model.predict(difference_image)\n",
    "\n",
    "print(f\"Prediction (0 for Authentic, 1 for Tampered): {prediction[0]}\")\n",
    "if prediction[0] > 0.5:\n",
    "    print(\"The image is likely tampered.\")\n",
    "else:\n",
    "    print(\"The image is likely authentic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a753540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_difference_example(authentic_dir, tampered_dir):\n",
    "    # Pick a random tampered image\n",
    "    tampered_files = [f for f in os.listdir(tampered_dir) if f.lower().endswith(('.jpg', '.tif'))]\n",
    "    chosen_file = np.random.choice(tampered_files)\n",
    "    tampered_img = cv2.imread(os.path.join(tampered_dir, chosen_file), cv2.IMREAD_COLOR)\n",
    "    tampered_img_resized = cv2.resize(tampered_img, (224, 224))\n",
    "\n",
    "    # Find its corresponding authentic image\n",
    "    parts = chosen_file.split(\"_\")\n",
    "    if len(parts) >= 7:\n",
    "        source_id = parts[4][:3] + \"_\" + parts[4][3:]\n",
    "        target_id = parts[5][:3] + \"_\" + parts[5][3:]\n",
    "        for id_ in [source_id, target_id]:\n",
    "            for ext in ['.jpg', '.bmp']:\n",
    "                auth_filename = f\"Au_{id_}{ext}\"\n",
    "                auth_filepath = os.path.join(authentic_dir, auth_filename)\n",
    "                if os.path.exists(auth_filepath):\n",
    "                    auth_img = cv2.imread(auth_filepath, cv2.IMREAD_COLOR)\n",
    "                    auth_img_resized = cv2.resize(auth_img, (224, 224))\n",
    "\n",
    "                    # Calculate difference image\n",
    "                    difference_img = calculate_difference_image(tampered_img_resized, auth_img_resized)\n",
    "\n",
    "                    # Display images\n",
    "                    plt.figure(figsize=(12, 4))\n",
    "                    plt.subplot(1, 3, 1)\n",
    "                    plt.imshow(cv2.cvtColor(tampered_img_resized, cv2.COLOR_BGR2RGB))\n",
    "                    plt.title('Tampered Image')\n",
    "                    plt.axis('off')\n",
    "\n",
    "                    plt.subplot(1, 3, 2)\n",
    "                    plt.imshow(cv2.cvtColor(auth_img_resized, cv2.COLOR_BGR2RGB))\n",
    "                    plt.title('Authentic Image')\n",
    "                    plt.axis('off')\n",
    "\n",
    "                    plt.subplot(1, 3, 3)\n",
    "                    plt.imshow(cv2.cvtColor(difference_img, cv2.COLOR_BGR2RGB))\n",
    "                    plt.title('Difference Image')\n",
    "                    plt.axis('off')\n",
    "\n",
    "                    plt.show()\n",
    "                    return\n",
    "\n",
    "    print(\"No matching example found or unable to load images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d62a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_difference_example('D:\\SASTRA Files\\Sem-6\\MINI PROJECT\\Digital Image Forgery Detection\\CASIA2 Dataset\\Au')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
